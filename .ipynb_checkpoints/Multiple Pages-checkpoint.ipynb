{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba13c268",
   "metadata": {},
   "source": [
    "# Lab | Web Scraping Multiple Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f097c6",
   "metadata": {},
   "source": [
    "# 1. Retrieve an arbitrary Wikipedia page of \"Python\" and create a list of links on that page: \n",
    "# url ='https://en.wikipedia.org/wiki/Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d34216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74d9f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find url and store it in a variable\n",
    "url = \"https://en.wikipedia.org/wiki/Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1216fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download html with a get request\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f79810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://en.wiktionary.org/wiki/Python', 'https://en.wiktionary.org/wiki/python', '/w/index.php?title=Python&action=edit&section=1', '/wiki/Pythonidae', '/wiki/Python_(genus)', '/wiki/Python_(mythology)', '/w/index.php?title=Python&action=edit&section=2', '/wiki/Python_(programming_language)', '/wiki/CMU_Common_Lisp', '/wiki/PERQ#PERQ_3', '/w/index.php?title=Python&action=edit&section=3', '/wiki/Python_of_Aenus', '/wiki/Python_(painter)', '/wiki/Python_of_Byzantium', '/wiki/Python_of_Catana', '/wiki/Python_Anghelo', '/w/index.php?title=Python&action=edit&section=4', '/wiki/Python_(Efteling)', '/wiki/Python_(Busch_Gardens_Tampa_Bay)', '/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)', '/w/index.php?title=Python&action=edit&section=5', '/wiki/Python_(automobile_maker)', '/wiki/Python_(Ford_prototype)', '/w/index.php?title=Python&action=edit&section=6', '/wiki/Python_(missile)', '/wiki/Python_(nuclear_primary)', '/wiki/Colt_Python', '/w/index.php?title=Python&action=edit&section=7', '/wiki/Python_(codename)', '/wiki/Python_(film)', '/wiki/Monty_Python', '/wiki/Python_(Monty)_Pictures', '/wiki/Timon_of_Phlius', '/w/index.php?title=Python&action=edit&section=8', '/wiki/Pyton', '/wiki/Pithon', '/wiki/File:Disambig_gray.svg', '/wiki/Help:Disambiguation', 'https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0', 'https://en.wikipedia.org/w/index.php?title=Python&oldid=1196720317']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the div element with id=\"mw-content-text\"\n",
    "    content_div = soup.find('div', id='mw-content-text')\n",
    "    \n",
    "    # Initialize a list to store links\n",
    "    links = []\n",
    "    \n",
    "    # Find all <a> tags within the content_div\n",
    "    for link in content_div.find_all('a', href=True):\n",
    "        links.append(link['href'])\n",
    "    \n",
    "    # Display the list of links\n",
    "    print(links)\n",
    "else:\n",
    "    print('Failed to retrieve data from the website')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9989939c",
   "metadata": {},
   "source": [
    "# 2.Find the number of titles that have changed in the United States Code since its last release point\n",
    "#: url = 'https://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed188b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find url and store it in a variable\n",
    "url = \"https://uscode.house.gov/download/download.shtml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92cb053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download html with a get request\n",
    "response2 = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89943110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the request was successful (status code 200)\n",
    "response2.status_code # 200 status code means OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eb3723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse html (create the 'soup')\n",
    "soup2 = BeautifulSoup(response2.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7ae6a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the html code looks like it should\n",
    "# print(soup2.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afa55bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"usctitlechanged\" id=\"us/usc/t2\">\n",
       " \n",
       "           Title 2 - The Congress\n",
       " \n",
       "         </div>,\n",
       " <div class=\"usctitlechanged\" id=\"us/usc/t5\">\n",
       " \n",
       "           Title 5 - Government Organization and Employees <span class=\"footnote\"><a class=\"fn\" href=\"#fn\">٭</a></span>\n",
       " </div>,\n",
       " <div class=\"usctitlechanged\" id=\"us/usc/t6\">\n",
       " \n",
       "           Title 6 - Domestic Security\n",
       " \n",
       "         </div>,\n",
       " <div class=\"usctitlechanged\" id=\"us/usc/t18\">\n",
       " \n",
       "           Title 18 - Crimes and Criminal Procedure <span class=\"footnote\"><a class=\"fn\" href=\"#fn\">٭</a></span>\n",
       " </div>,\n",
       " <div class=\"usctitlechanged\" id=\"us/usc/t19\">\n",
       " \n",
       "           Title 19 - Customs Duties\n",
       " \n",
       "         </div>,\n",
       " <div class=\"usctitlechanged\" id=\"us/usc/t42\">\n",
       " \n",
       "           Title 42 - The Public Health and Welfare\n",
       " \n",
       "         </div>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select(\"div.usctitlechanged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b04d52f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0a5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1063eb2f",
   "metadata": {},
   "source": [
    "# 3. Display the top 10 languages by number of native speakers stored in a pandas dataframe: \n",
    "# url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f7a136e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language Rank   Native Speakers\n",
      "0             1  Mandarin Chinese\n",
      "1             2           Spanish\n",
      "2             3           English\n",
      "3             3            Arabic\n",
      "4             5             Hindi\n",
      "5             6           Bengali\n",
      "6             7        Portuguese\n",
      "7             8           Russian\n",
      "8             9          Japanese\n",
      "9            10   Western Punjabi\n"
     ]
    }
   ],
   "source": [
    "# Send a GET request to the URL\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the table with class 'wikitable sortable'\n",
    "table = soup.find('table', class_='wikitable sortable')\n",
    "\n",
    "# Extract the rows from the table\n",
    "rows = table.find_all('tr')[1:11]  # Skip the header row, take only top 10 languages\n",
    "\n",
    "# Initialize lists to store language data\n",
    "languages = []\n",
    "native_speakers = []\n",
    "\n",
    "# Iterate through each row and extract language data\n",
    "for row in rows:\n",
    "    columns = row.find_all('td')\n",
    "    language = columns[0].text.strip()\n",
    "    speakers = columns[1].text.strip()\n",
    "    languages.append(language)\n",
    "    native_speakers.append(speakers)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "data = {'Language Rank': languages, 'Native Speakers': native_speakers}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60bc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca90e60e",
   "metadata": {},
   "source": [
    "# 4.A list with the different kind of datasets available in data.gov.uk: url = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cf12424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: Business and economy\n",
      "Description: Small businesses, industry, imports, exports and trade\n",
      "\n",
      "Topic: Crime and justice\n",
      "Description: Courts, police, prison, offenders, borders and immigration\n",
      "\n",
      "Topic: Defence\n",
      "Description: Armed forces, health and safety, search and rescue\n",
      "\n",
      "Topic: Education\n",
      "Description: Students, training, qualifications and the National Curriculum\n",
      "\n",
      "Topic: Environment\n",
      "Description: Weather, flooding, rivers, air quality, geology and agriculture\n",
      "\n",
      "Topic: Government\n",
      "Description: Staff numbers and pay, local councillors and department business plans\n",
      "\n",
      "Topic: Government spending\n",
      "Description: Includes all payments by government departments over £25,000\n",
      "\n",
      "Topic: Health\n",
      "Description: Includes smoking, drugs, alcohol, medicine performance and hospitals\n",
      "\n",
      "Topic: Mapping\n",
      "Description: Addresses, boundaries, land ownership, aerial photographs, seabed and land terrain\n",
      "\n",
      "Topic: Society\n",
      "Description: Employment, benefits, household finances, poverty and population\n",
      "\n",
      "Topic: Towns and cities\n",
      "Description: Includes housing, urban planning, leisure, waste and energy, consumption\n",
      "\n",
      "Topic: Transport\n",
      "Description: Airports, roads, freight, electric vehicles, parking, buses and footpaths\n",
      "\n",
      "Topic: Digital service performance\n",
      "Description: Cost, usage, completion rate, digital take-up, satisfaction\n",
      "\n",
      "Topic: Government reference data\n",
      "Description: Trusted data that is referenced and shared across government departments\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Send a GET request to the URL\n",
    "url = \"https://www.data.gov.uk/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the unordered list with class 'govuk-list dgu-topics__list'\n",
    "ul = soup.find('ul', class_='govuk-list dgu-topics__list')\n",
    "\n",
    "# Extract all list items from the unordered list\n",
    "dataset_topics = ul.find_all('li')\n",
    "\n",
    "# Iterate through each list item and print the topic and description\n",
    "for topic in dataset_topics:\n",
    "    topic_name = topic.find('h3', class_='govuk-heading-s dgu-topics__heading').text.strip()\n",
    "    description = topic.find('p', class_='govuk-body').text.strip()\n",
    "    print(\"Topic:\", topic_name)\n",
    "    print(\"Description:\", description)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28562452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
